{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a0aa54-6472-4ab3-8df5-5e8e2367d9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f094a-64af-4b0d-b916-86f6e95c9b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sentence = 50000\n",
    "# with open(\"text/shakespear.txt\", \"r\") as file:\n",
    "#     corpus = file.read()[max_sentence:max_sentence*2].lower()\n",
    "convs = pd.read_csv(\"Conversation.csv\")[:max_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defe81c-27ed-42dc-9782-0402010d47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\n",
    "for t in convs[\"question\"]:\n",
    "    corpus += t + \" \"\n",
    "for t in convs[\"answer\"]:\n",
    "    corpus += t + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25957964-6168-42b0-beb3-d6a8e7ac68b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make cuts to generate data\n",
    "num_examples = 500000\n",
    "max_text_length = 100\n",
    "x_train_text = []\n",
    "\n",
    "for i in range(num_examples):\n",
    "    start = i * max_text_length\n",
    "    end = start + max_text_length\n",
    "    if end > len(corpus):\n",
    "        continue\n",
    "    text = corpus[start:end]\n",
    "    \n",
    "    x_train_text.append(text)\n",
    "\n",
    "\n",
    "# generate the one hot vectors for the characters\n",
    "\n",
    "characters = set()\n",
    "for c in corpus:\n",
    "    characters.add(c)\n",
    "    \n",
    "    \n",
    "len_characters = len(characters)\n",
    "\n",
    "character_index = {}\n",
    "\n",
    "for i, c in enumerate(characters):\n",
    "    character_index[c] = i + 1\n",
    "\n",
    "    \n",
    "def character_to_one_hot(c):\n",
    "    index = character_index.get(c)\n",
    "    vec = np.array([(i + 1 == index) for i in range(len_characters)], dtype=np.float32)\n",
    "    return vec\n",
    "\n",
    "x_train = []\n",
    "\n",
    "for text in x_train_text:\n",
    "    x = np.array([character_to_one_hot(c) for c in text[:-1]])\n",
    "    # if x.shape[0] > max_text_length:\n",
    "    #     x = x[:max_text_length]\n",
    "    # while x.shape[0] < max_text_length:\n",
    "    #     # print(\"still small\")\n",
    "    #     x = np.vstack([x, np.array([0 for _ in range(len_characters)])])\n",
    "    x_train.append(x)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "# y_train = np.array([character_to_one_hot(text[-1]) for text in x_train_text])\n",
    "y_train = x_train[:, 1:, :]\n",
    "x_train = x_train[:, :-1, :]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b2c09-d9d1-4972-8783-456745367ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5e6ac-190f-4425-8465-c4587e2cf801",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.GRU(units=128, input_shape=(None, len_characters), return_sequences=True),\n",
    "    layers.GRU(units=128, return_sequences=True),\n",
    "    # layers.GRU(units=64, return_sequences=True),\n",
    "    layers.Dense(units=len_characters, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8bf232-cfa5-421e-9537-cad84647d7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"i\"\n",
    "length = 50\n",
    "total_dashes = 20\n",
    "for i in range(length):\n",
    "    x_input = []\n",
    "    sent = sentence\n",
    "    if len(sentence) > max_text_length:\n",
    "        sent = sentence[len(sent) - max_text_length:]\n",
    "    for s in sent:\n",
    "        ohv = character_to_one_hot(s)\n",
    "        x_input.append(ohv)\n",
    "    x_input = np.array(x_input)\n",
    "    y_pred = model.predict(np.array([x_input]), verbose=None)[:, -1, :].reshape(-1, len_characters)\n",
    "    c = tf.random.categorical(tf.math.log(y_pred), 1)\n",
    "    c = c.numpy()[0] + 1\n",
    "    for char in character_index.keys():\n",
    "        if character_index[char] == c:\n",
    "            c = char\n",
    "            break\n",
    "    sentence += c\n",
    "    t = i/(length - 1)\n",
    "    num_dashes = int(total_dashes * (1 - t))\n",
    "    num_stars = int(total_dashes * t)\n",
    "    print(\"\\r\" + (\".\"*num_stars) + (\"-\"*num_dashes), end=\"\")\n",
    "print(\"\\r\", sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
